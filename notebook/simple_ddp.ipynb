{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DistributedSampler\n",
    "\n",
    "# Common configuration values for distributed training.\n",
    "nnode = 2 # Number of nodes(mahcines)\n",
    "#gpu_per_node = 4 # Number of GPUs(Processes) per node.\n",
    "gpu_per_node = [2, 4] # Or you can make a list for number of GPUs in case that each machine has different num of them.\n",
    "backend = 'nccl' # Backend. Read pytorch.DDP document for more details.\n",
    "init_method = 'env://' # Current Value is default. Read pytorch.DDP document for more details.\n",
    "master_addr = '127.0.0.1' # Master address. Replace with the IP address of Node 0.\n",
    "master_port = '12345' # Master Port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual node configuration. You have to edit this part for each node(machine)\n",
    "node = 0 # Node ID. 0 is the Master node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "\n",
    "# Define your model and data here\n",
    "nn_model = torch.nn.Module() # Replace your own model to use.\n",
    "dataset = Dataset() # Replace your own dataset.\n",
    "\n",
    "batch_size = 100 # Replace with your own batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProcessExitedException",
     "evalue": "process 1 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-de9b0100a106>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mlocal_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpu_per_node\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0m_rank0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpu_per_node\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist_main\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_rank0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\multiprocessing\\spawn.py\u001b[0m in \u001b[0;36mspawn\u001b[1;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[0;32m    238\u001b[0m                ' torch.multiprocessing.start_processes(...)' % start_method)\n\u001b[0;32m    239\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstart_processes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'spawn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\multiprocessing\\spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[1;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\multiprocessing\\spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    147\u001b[0m                 )\n\u001b[0;32m    148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m                 raise ProcessExitedException(\n\u001b[0m\u001b[0;32m    150\u001b[0m                     \u001b[1;34m\"process %d terminated with exit code %d\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProcessExitedException\u001b[0m: process 1 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    #Write your own code here\n",
    "    pass\n",
    "\n",
    "def infer():\n",
    "    #Write your own code here\n",
    "    pass\n",
    "\n",
    "def dist_main(local_rank:int, world_size:int, _rank0:int)->None:\n",
    "    r'''Entry point for each process.\n",
    "    The first argument is always local rank which is provided by torch.mp.\n",
    "    '''\n",
    "    global_rank = local_rank + _rank0\n",
    "\n",
    "    os.environ['MASTER_ADDR'] = master_addr\n",
    "    os.environ['MASTER_PORT'] = master_port\n",
    "\n",
    "    dist.init_process_group(backend, init_method, world_size=world_size, rank=global_rank)\n",
    "\n",
    "    sampler = DistributedSampler(dataset, world_size, global_rank)\n",
    "    # Replace the arguments as you wish except the sampler if you don't define your own distributed sampler.\n",
    "    dataloader = DataLoader(dataset, batch_size, sampler=sampler, num_workers=4, pin_memory=True)\n",
    "    ddp_model = DDP(nn_model.to(local_rank), device_ids=[local_rank])\n",
    "\n",
    "    # Do Something Here\n",
    "    # train()...\n",
    "    # infer()...\n",
    "\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if isinstance(gpu_per_node, int):\n",
    "        world_size = nnode * gpu_per_node\n",
    "        local_size = gpu_per_node\n",
    "        _rank0 = node * gpu_per_node\n",
    "    elif isinstance(gpu_per_node, list):\n",
    "        world_size = sum(gpu_per_node)\n",
    "        local_size = gpu_per_node[node]\n",
    "        _rank0 = sum(gpu_per_node[0:node])\n",
    "    mp.spawn(dist_main, (world_size, _rank0), local_size, join=True, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
